<!DOCTYPE html>

<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="description" content="Data Munging &amp; Reskilling Workshop" />
    <title>Data Munging &amp; Reskilling Workshop</title>
    <script src="./js/remark-0.6.0.min.js" type="text/javascript"></script>
    <style type="text/css">
      @font-face {
        font-family: 'Cutive Mono';
        font-style: normal;
        font-weight: normal;
        src: local('Cutive Mono'), url(./fonts/Cutive_Mono.woff2) format('woff2');
      }
      @font-face {
        font-family: 'Yanone Kaffeesatz';
        font-style: normal;
        font-weight: normal;
        src: local('Yanone Kaffeesatz'), url(./fonts/Yanone_Kaffeesatz.woff) format('woff');
      }
      body {
        font-family: 'Cutive Mono';
        font-size: 26px;
        color: #2F302D;
      }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: 400;
        margin-bottom: 0;
      }
      h1 { font-size: 4em; color: #334C00; }
      h2 { font-size: 3em; color: #334C00; }
      h3 { font-size: 2em; color: #334C00; }
      small { font-size: 0.5em; }
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      .large { font-size: 2em; }
      a, a > code {
        color: #334C00;
        text-decoration: none;
      }
      img {
      max-width: 725px;
      max-height: 550px;
      }
      code {
        -moz-border-radius: 5px;
        -web-border-radius: 5px;
        background: #e7e8e2;
        border-radius: 5px;
        font-size: 16px;
      }
      .pull-left {
        float: left;
        width: 47%;
      }
      .pull-right {
        float: right;
        width: 47%;
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .inverse {
        background: #272822;
        color: #777872;
        /*text-shadow: 0 0 20px #333;*/
      }
      .inverse h1, .inverse h2 {
        color: #f3f3f3;
        line-height: 0.8em;
      }

      /* Slide-specific styling */
      #slide-inverse .footnote {
        bottom: 12px;
        left: 20px;
      }
      #slide-how .slides {
        font-size: 0.9em;
        position: absolute;
        top:  151px;
        right: 140px;
      }
      #slide-how .slides h3 {
        margin-top: 0.2em;
      }
      #slide-how .slides .first, #slide-how .slides .second {
        padding: 1px 20px;
        height: 90px;
        width: 120px;
        -moz-box-shadow: 0 0 10px #777;
        -webkit-box-shadow: 0 0 10px #777;
        box-shadow: 0 0 10px #777;
      }
      #slide-how .slides .first {
        background: #fff;
        position: absolute;
        top: 20%;
        left: 20%;
        z-index: 1;
      }
      #slide-how .slides .second {
        position: relative;
        background: #fff;
        z-index: 0;
      }

      /* Two-column layout */
      .left-column {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
      .right-column {
        width: 70%;
        float: right;
        padding-top: 2em;
      }
    </style>
  </head>
  <body>
    <textarea id="source">
class: center middle
#Data Munging &amp; Reskilling Workshop
###Royal Library, Copenhagen, 2015

Christina Harlow

cmharlow@gmail.com, @cm_harlow

---
class: center middle
##Slides &amp; Examples
http://bit.ly/dataMunging

---
class: middle
##Who is this Christina person

- *Former*: Metadata Specialist, Columbia University
- *Current*: Head of Cataloging &amp; Metadata, University of Tennessee Knoxville
- *Current*: Metadata lead, Digital Library of Tennessee (DPLA Service hub)
- *2016*: Metadata Librarian, Cornell University

---
class: middle
##Who is this Christina person

Thinks a lot about:

- Cataloger reskilling
- Developer <=> Metadataist bridges
- Library Data Tools
- Side Benefits of Linked Open Data
- christinaharlow.com

---
class: center middle
## Left-sharking It

![Left-sharking](img/left-shark2.jpg "Left-sharking")

---
class: middle
##Right Now
*1st hour:*

- metadata munging tools, use cases, examples
- changing role of cataloging discussions

*2nd hour:*

- break outs, more details/help on tools of interest

---
class: center middle
##Use Case 1: What Data Do We Have?

*Columbia*: Omeka => Hydra, preparing for Voyager => Alma

*UTK*: at least 4 platforms => Alma, Islandora

*DPLA*: Aggregating 225000 records from mostly ContentDM, Dspace => Repox (to DPLA)

*First question*: What does this data look like?

---
class: middle
##Use Case 1: What Data Do We Have?

Tools:

- [UNT Work: Harvester](https://github.com/vphill/pyoaiharvester)
- [UNT Work: Metadata Breakers](https://github.com/vphill/metadata_breakers)
- [Mark Phillips, *Metadata Analysis at the Command Line*](http://journal.code4lib.org/articles/7818)
- [Corey Harper, *Can Metadata be Quantified*](https://dplafest2015.sched.org/event/f834f6065d32f940ac409b240c73323f)
- [UTK Metadata QA Scripts](https://github.com/cmh2166/metadataQA)
- Simple [PyMARC](http://github.com/edsu/pymarc) Usages

---
class: center middle
##Python
Python = a popular, high-level programming language used for a variety of purposes. PyMARC is a Python library helpful for working with MARC data.

python wiki: https://wiki.python.org/moin/
pymarc: https://github.com/edsu/pymarc

---
class: middle
.left-column[
  ###Python Scripting
]
.right-column[

- Highly customizable for special projects' data

- Works with all types of data through use of libraries

- Runs through larger datasets more quickly

- Requires programming knowledge

- Requires often building scripts locally

]

---
class: middle
##Python QA at UTK, DLTN

  - UNT-based OAI scripts
  - DPLA Json objects review

---
class: middle center
###Python Reports at UTK, DLTN
*OAI-DC script excerpt*

![Main method from OAI DC analysis script](img/OAIDCreview.png)
<small>github.com/cmh2166/metadataQA</small>

---
class: middle center
###Python Reports at UTK, DLTN
*OAI-DC script report*

![OAIDC Field report](img/OAIDCreport.png)
<small>github.com/cmh2166/metadataQA</small>

---
class: middle center
*OAI-MODS script report*
![OAIMODS Field Report](img/OAIMODSreport.png)
<small>github.com/cmh2166/metadataQA</small>


---
class: middle center
###Python Reports at UTK, DLTN
*OAI script field report*
![OAI DC Format Fields Shown](img/OAIDCfields.png)

<small>github.com/cmh2166/metadataQA</small>

---
class: middle center
###Python Reports at UTK, DLTN
*OAIMODS script XPath report*
![OAIMODS EDTF-compliant dates](img/OAIMODSedtfdate.png)
<small>github.com/cmh2166/metadataQA</small>

---
class: middle center
###Python Reports at UTK, DLTN
**DPLA Json objects script excerpt**
![DPLA Analysis script get elements function](img/DPLAgetelements.png)
<small>github.com/cmh2166/metadataQA</small>

---
class: middle center
###Python Reports at UTK, DLTN
**DPLA Json objects report excerpt**
![Start of DPLA data providers with items that have date of creation post 2020](img/DPLAprovider2020.png)
<small>github.com/cmh2166/metadataQA</small>

---
class: middle center
##Use Case 2: Vendor-supplied MARC Review, Enhance

*Question*: How to get catalogers batch reviewing, enhancing vendor-supplied records?

---
class: middle center
##Use Case 2.5: Adding URIs to MARC

*Question*: How to get catalogers adding $0 URIs in batch to controlled access points MARC records?

---
class: middle
##Use Case 2: MARC Review, Enhance

Tools:

[MarcEdit](http://marcedit.reeset.net/) = Freely available (but not open source) tool for working with MARC records.

[Catmandu MARC Reports](http://journal.code4lib.org/articles/11013)

---
class: center middle
##MARCEdit

MarcEdit = Freely available (but not open source) tool for working with MARC records developed and maintained by Terry Reese of Ohio State University.

http://marcedit.reeset.net/

---
class: center middle
###MarcEdit Screenshot
![Screenshot of MarcEdit Windows](img/marcEditScreen.png)

---
class: middle
.left-column[
  ###MarcEdit
]
.right-column[

- Easy to learn

- Work with .mrc, .mrk, or MARC/XML

- Standard conversions

- Validates MARC, RDA Helper

- Generates reports

- Performance issues for bigger (>50k) sets

- Not always/easily customizable

]
---
class: middle
##MarcEdit at UTK

- [MARCEdit Ebooks Review Workflow](https://wiki.lib.utk.edu/display/CAT/MARCEdit+E-Resource+Batch+Preparation)
- [MARCEdit Next Tools](https://docs.google.com/document/d/1YNV7pWyxCZ0qCh5p3I3-Bi2NL3amQUzl-yP5_7LRKd4/edit?usp=drive_web)
- [Alma Import Profiles, Data Export](https://na02.alma.exlibrisgroup.com/mng/action/home.do?mode=ajax#b)

---
class: center middle
##Catmandu
Catmandu = data toolkit (command line client and Perl modules) developed as part of the LibreCat project

http://librecat.org/Catmandu/

---
class: middle
.left-column[
  ###Catmandu Perl Scripts
]
.right-column[

- Highly customizable

- Works with all types of data

- Can be part of ETL process with many different data stores, engines, platforms, etc.

- Works well with larger datasets (>100k records)

- Requires some programming knowledge

- Installing Perl, Catmandu &amp; dependencies can be tricky

]

---
class: middle
##Catmandu at UTK

  - Saved fix routines
  - MARC value reports for big sets (when MARCEdit has trouble)

---
.left-column[
  ###Catmandu at UTK
  *MARC URI Fix routine excerpt*
]
.right-column[
  ![Start of MARC URI/Recon checking report](img/MARCreconfix.png)
  <small>examples > Catmandu > MARCreconReport.fix</small>
]

---
.left-column[
  ###Catmandu at UTK
  *MARC URI - Fix routine YAML report*
]
.right-column[
  ![Start of the MARC Recon YAML output/report](img/MARCreconYAMLreport.png)
  <small>examples > Catmandu > MARCreconReport.yaml</small>
]

---
class: center middle
###Catmandu at UTK
**MARC General CSV Report, Fix routine Excerpt**
![Excerpt of General MARC CSV Report Fix](img/MARCgeneralReport.png)
<small>examples > Catmandu > MARCgeneralReport.fix</small>

---
class: center middle
###Catmandu at UTK, DLTN
**Fix routine for MARC Report**

![Start of the MARC general CSV report in Numbers](img/MARCgeneralCSV.png)
<small>examples > Catmandu > MARCgeneralReport.csv</small>

---
class: center middle
##Use Case 3: Metadata Worflows

*Question*: How to handle metadata creation by content specialists, review + enhancement by catalogers, then transform to XML for loading by developers?

*Question*: How does the above change for migrations?

---
class: middle
## Use Case 3: Metadata Workflows
Tools:

- [Google Sheets with limited Data Validation](https://docs.google.com/spreadsheets/d/1pmWl8cciKMIqj3Xr3EPUNO5_OztlceSR72EQMg76o6U/edit?usp=sharing)
- OpenRefine: [Catalogers' Uses](http://journal.code4lib.org/articles/11013) &amp; [Catalogers' Reskilling](http://christinaharlow.com/notes-on-being-a-metadata-supervisor/)
- [OpenRefine - Reconciliation and URI, external data retrieval](https://github.com/cmh2166/c4lMDCpres)
- Limitations of work currently at UTK
- [Digital Library of Tennessee Work](https://wiki.lib.utk.edu/display/DPLA/Digital+Library+of+Tennessee+%28DLTN%29+Home)

---
class: center middle
###OpenRefine Screenshot
![Screenshot of the OpenRefine Interface](img/openRefineScreenshot.png)

---
class: middle
.left-column[
  ###OpenRefine
]
.right-column[

- Helpful Graphical User Interface for understanding data

- Works with many types of data (better with flatter)

- Faceting, Clustering, GREL, Reconciliation

- Exports a number of formats/encodings

- Performance issues for bigger (>150k) sets

]

---
class: center middle
## OpenRefine Reconciliation

Reconciliation broadly: Compare values in my dataset with values in an external dataset, if deemed a match, link and pull in external datapoint information

---
class: middle
## OpenRefine Recon Options

  * Add column by fetching URL...
    * HTTP requests to external data API in UI
    * takes far longer to pull data
    * requires parsing returned data with GREL

---
class: middle
## OpenRefine Recon Options

  * Standard Recon Service API
    * RESTful API between OpenRefine and external data
    * requires tinkering knowledge of API building
    * can host for easier use

---
class: middle
## OpenRefine Recon Options

  * DERI RDF Extension
    * no longer actively supported
    * Standard Recon Service API to work with RDF, SPARQL endpoints
    * RDF docs held in memory
    * SPARQL recon dependent on SPARQL server details

---
class: middle
## Add column by fetching URL...

 * 'Edit column' > 'Add column by fetching URLs'
 * Give the results column a name
 * Enter the GREL to create the API URL query, then 'Add column'
 * Wait possibly a very, very long time
 * Use GREL on the results column to parse response

---
class: middle
## Examples: Add column by fetching URL...

  * Check 'addcolumnexamples.md' in this workshop's GitHub repo.
  * Also review the Mountain West Digital Library workflow using this method with the Geonames API

---
class: center middle
## Standard Recon Service API

OpenRefine Standard Reconciliation Service takes UI data, queries external dataset, then handles ranking, normalization, and returning results to UI.

= HTTP-based RESTful JSON-formatted API connecting OpenRefine to external datasets. This API can be constructed in a number of languages and frameworks.

Originally based off of Freebase extension (no longer working).

---
class: middle
## Standard Recon Service API Parts

  * Recon Service Endpoint
    * GET to send service info to OpenRefine
    * POST to query data API for matches
  * Recon Service Metadata
  * Entity 'Types'
    * Freebase holdover
  * Query/Response Handling
  * Other bells and whistles

---
class: center middle
## Recon Service API Metadata

"When a service is called with just a JSONP callback parameter and no other parameters, it must return its metadata as a JSON object literal with at least 3 fields 'name', 'identifierSpace', and 'schemaSpace'. Other fields are optional for reconciliation services which can make use of the default Freebase preview, suggest, etc services, but non-Freebase reconciliation services may need to implement them all."

<small>https://github.com/OpenRefine/OpenRefine/wiki/Reconciliation-Service-API</small>

---
class: middle
## API Metadata Example Part 1

```
{
  "name" : "Reconciliation Service Name",
  "identifierSpace" : "http://rdf.freebase.com/ns/some.name.space",
  "schemaSpace" : "http://rdf.freebase.com/ns/type.object.id",
  "view" : {
    "url" : "http://www.externaldatasource.org//{{id}}"
  },
  "preview" : {
    "url" : "http://this-api.freebaseapps.com/preview/{{id}}",
    "width" : 430,
    "height" : 300
  },
```

---
class: middle
## API Metadata Example Part 2

```
  "suggest" : {
    "type" : {
      "service_url" : "http://this-api.freebaseapps.com",
      "service_path" : "/suggest_type",
      "flyout_service_url" : "http://www.freebase.com"
    },
    "property" : {
      "service_url" : "http://this-api.freebaseapps.com",
      "service_path" : "/suggest_property",
      "flyout_service_url" : "http://www.freebase.com"
    },
    "entity" : {
      "service_url" : "http://this-api.freebaseapps.com",
      "service_path" : "/suggest",
      "flyout_service_path" : "/flyout"
    }
  },
  "defaultTypes" : []
}
```

---
class: middle
## Query JSON Example

```
  {
    "query" : "Kittens",
    "limit" : 3,
    "type" : "/fast/all",
    "type_strict" : "any"
  }
```

---
class: middle
## Reconciled JSON Example

```
{
    "result" : [
      {
        "id" : "http://id.loc.gov/authorities/subjects/sh85072589"
        "name" : "Kittens"
        "type" : "/fast/all"
        "match" : "false"
      },
      ... more results ...
    ]
  }
```

---
class: center middle
## Entity Types

These are the types of entities for reconciliation, usually based on the result

Depends on the service and is optional. Freebase holdover that can be used to access different indexes for an external data API.

---
class: center middle
## Standard Recon Service API Templates

Some wonderful developers made templates in a variety of languages, though python/flask seems to be the language/framework du jour, for folks to plug in external data API information. These will get a basic API service up and running fairly quickly for those with limited programming knowledge or time.

---
class: middle
## Standard Recon Service Examples

* FAST Reconciliation Service (not hosted, using python)
  * Check 'pythonflaskmarkedupexample.md' in this workshop's GitHub repo.
* LCNAF - VIAF Reconciliation Service (hosted and not hosted, using python)
* VIAF Reconciliation Service Example (hosted, using PHP)
* Basic Python/Flask Template
* Extended Python/Flask Template

---
class: center middle
## DERI RDF Extension Recon

Using this, can reconcile against RDF documents and SPARQL Endpoints.

**No longer actively supported.**

---
class: center middle
##Use Case 4: Local Authorities

*Question*: How to get the Great Smoky Mountains Regional Collection as a local authority that effectively extends Geonames, the Library of Congress Authorities?

---
class: middle
##Use Case 4: Local Authorities
Tools

- [LODRefine - Exporting Local Authorities as SKOS RDF](http://christinaharlow.com/moving-beyond-authorities-accessyyz-speaker-notes/)
- [Skosmos](http://skosmos.org/)
- [SKOSify](https://github.com/NatLibFi/Skosify)

---
class:middle
##Local Authorities Example

```
<http://dots.lib.utk.edu/p54274> <rdfs#type> <skos#Concept> .
<p54274> <skos#prefLabel> "Tellico"@en .
<p54274> <skos#inScheme> <http://dots.lib.utk.edu/DOTS> .
<p54274> <skos#altLabel> "Talequo"@en .
<p54274> <skos#related> <http://id.loc.gov/authorities/names/no94017139> .
<p54274> <skos#related> <http://id.loc.gov/authorities/names/n86034608> .
<p54274> <skos#related> <http://sws.geonames.org/4662016/> .
```

<small>apologies for the invalid/shrunken Ntriples here - this was done just for slide space considerations.</small>

---
class: center middle
##Links &amp; Thank you

Christina Harlow

cmharlow@gmail.com

@cm_harlow

http://bit.ly/dataMunging

    </textarea>
    <div id="slideshow"></div>
    <script type="text/javascript">
        var slideshow = remark.create({
            highlightLanguage: 'no-highlight',
            highlightStyle: 'zenburn',
        });
    </script>
  </body>
</html>
